{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install imutils"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","import random \n","import cv2\n","import imutils\n","import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras import optimizers\n","from sklearn.preprocessing import LabelBinarizer\n","from keras import backend as K\n","from keras.layers import Dense, Activation, Flatten, Dense,MaxPooling2D, Dropout\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dir = \"../input/handwritten-characters/Train/\"\n","train_data = []\n","img_size = 32\n","non_chars = [\"#\",\"$\",\"&\",\"@\"]\n","for i in os.listdir(dir):\n","    if i in non_chars:\n","        continue\n","    count = 0\n","    sub_directory = os.path.join(dir,i)\n","    for j in os.listdir(sub_directory):\n","        count+=1\n","        if count > 4000:\n","            break\n","        img = cv2.imread(os.path.join(sub_directory,j),0)\n","        img = cv2.resize(img,(img_size,img_size))\n","        train_data.append([img,i])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_dir = \"../input/handwritten-characters/Validation/\"\n","val_data = []\n","img_size = 32\n","for i in os.listdir(val_dir):\n","    if i in non_chars:\n","        continue\n","    count = 0\n","    sub_directory = os.path.join(val_dir,i)\n","    for j in os.listdir(sub_directory):\n","        count+=1\n","        if count > 1000:\n","            break\n","        img = cv2.imread(os.path.join(sub_directory,j),0)\n","        img = cv2.resize(img,(img_size,img_size))\n","        val_data.append([img,i])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(val_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["random.shuffle(train_data)\n","random.shuffle(val_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_X = []\n","train_Y = []\n","for features,label in train_data:\n","    train_X.append(features)\n","    train_Y.append(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_X = []\n","val_Y = []\n","for features,label in val_data:\n","    val_X.append(features)\n","    val_Y.append(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["LB = LabelBinarizer()\n","train_Y = LB.fit_transform(train_Y)\n","val_Y = LB.fit_transform(val_Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_X = np.array(train_X)/255.0\n","train_X = train_X.reshape(-1,32,32,1)\n","train_Y = np.array(train_Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_X = np.array(val_X)/255.0\n","val_X = val_X.reshape(-1,32,32,1)\n","val_Y = np.array(val_Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(train_X.shape,val_X.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(train_Y.shape,val_Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(32,32,1)))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n"," \n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(35, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(train_X,train_Y, epochs=50, batch_size=32, validation_data = (val_X, val_Y),  verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Training Accuracy vs Validation Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Training Loss vs Validation Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def sort_contours(cnts, method=\"left-to-right\"):\n","    reverse = False\n","    i = 0\n","    if method == \"right-to-left\" or method == \"bottom-to-top\":\n","        reverse = True\n","    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n","        i = 1\n","    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n","    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n","    key=lambda b:b[1][i], reverse=reverse))\n","    # return the list of sorted contours and bounding boxes\n","    return (cnts, boundingBoxes)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_letters(img):\n","    letters = []\n","    image = cv2.imread(img)\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    ret,thresh1 = cv2.threshold(gray ,127,255,cv2.THRESH_BINARY_INV)\n","    dilated = cv2.dilate(thresh1, None, iterations=2)\n","\n","    cnts = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n","    cnts = imutils.grab_contours(cnts)\n","    cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n","    # loop over the contours\n","    for c in cnts:\n","        if cv2.contourArea(c) > 10:\n","            (x, y, w, h) = cv2.boundingRect(c)\n","            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","        roi = gray[y:y + h, x:x + w]\n","        thresh = cv2.threshold(roi, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n","        thresh = cv2.resize(thresh, (32, 32), interpolation = cv2.INTER_CUBIC)\n","        thresh = thresh.astype(\"float32\") / 255.0\n","        thresh = np.expand_dims(thresh, axis=-1)\n","        thresh = thresh.reshape(1,32,32,1)\n","        ypred = model.predict(thresh)\n","        ypred = LB.inverse_transform(ypred)\n","        [x] = ypred\n","        letters.append(x)\n","    return letters, image\n","\n","#plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_word(letter):\n","    word = \"\".join(letter)\n","    return word"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["letter,image = get_letters(\"../input/handwriting-recognition/train_v2/train/TRAIN_00003.jpg\")\n","word = get_word(letter)\n","print(word)\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["letter,image = get_letters(\"../input/handwriting-recognition/train_v2/train/TRAIN_00023.jpg\")\n","word = get_word(letter)\n","print(word)\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["letter,image = get_letters(\"../input/handwriting-recognition/train_v2/train/TRAIN_00030.jpg\")\n","word = get_word(letter)\n","print(word)\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["letter,image = get_letters(\"../input/handwriting-recognition/validation_v2/validation/VALIDATION_0005.jpg\")\n","word = get_word(letter)\n","print(word)\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["letter,image = get_letters(\"../input/handwriting-recognition/test_v2/test/TEST_0007.jpg\")\n","word = get_word(letter)\n","print(word)\n","plt.imshow(image)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":53376,"sourceId":101598,"sourceType":"datasetVersion"},{"datasetId":818027,"sourceId":1400106,"sourceType":"datasetVersion"}],"dockerImageVersionId":30042,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
